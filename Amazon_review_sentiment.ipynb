{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this ongoing project, I explore different methods for analyzing the sentiment of Amazon product reviews. I employ a dataset of text reviews and corresponding products ratings assigned by each reviewer as labelled training data, and predict product ratings on a test data set. I compare the predictive power of different approaches to text preprocessing with both na√Øve Bayes and support vector machine (SVM) models.\n",
    "\n",
    "# Load and Tidy Data\n",
    "\n",
    "I first need to import the packages I will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import time\n",
    "import re\n",
    "import scipy\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn import svm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use data from Julian McAuley's [Amazon product dataset](http://jmcauley.ucsd.edu/data/amazon/). To begin, I will use the [subset of Toys and Games data](http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Toys_and_Games_5.json.gz). Start by loading the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # read entire file\n",
    "# with open('reviews_Toys_and_Games_5.json', 'rb') as f:\n",
    "#     data = f.readlines()\n",
    "    \n",
    "# # remove the trailing \"\\n\" from each element\n",
    "# data = map(lambda x: x.rstrip(), data)\n",
    "# print 'number reviews:', len(data)\n",
    "\n",
    "# # for now, let's restrict to the first 30k obs\n",
    "# # (if I want to run with the full dataset, will probably need to use ec2)\n",
    "# data = data[:50000]\n",
    "\n",
    "# # convert list to a dataframe\n",
    "# t1 = time.time()\n",
    "# df = pd.DataFrame()\n",
    "# count = 0\n",
    "# for r in data:\n",
    "#     r = ast.literal_eval(r)\n",
    "#     s  = pd.Series(r,index=r.keys())\n",
    "#     df = df.append(s,ignore_index=True)\n",
    "#     if count % 1000 ==0:\n",
    "#         print count\n",
    "#     count+=1\n",
    "# t_process = time.time() - t1\n",
    "# print 'process time (seconds):', t_process  #takes 8s for 1000, so should take 8*167/60=22min for 167k\n",
    "# del data\n",
    "\n",
    "# # the above step is slow, so let's write this to csv so we don't have to do it again\n",
    "# df.to_csv('Toys_and_Games.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 9)\n",
      "         asin helpful  overall  \\\n",
      "0  0439893577  [0, 0]      5.0   \n",
      "1  0439893577  [1, 1]      4.0   \n",
      "2  0439893577  [1, 1]      5.0   \n",
      "\n",
      "                                          reviewText   reviewTime  \\\n",
      "0  I like the item pricing. My granddaughter want...  01 29, 2014   \n",
      "1  Love the magnet easel... great for moving to d...  03 28, 2014   \n",
      "2  Both sides are magnetic.  A real plus when you...  01 28, 2013   \n",
      "\n",
      "       reviewerID    reviewerName  \\\n",
      "0  A1VXOAVRGKGEAK           Angie   \n",
      "1   A8R62G708TSCM         Candace   \n",
      "2  A21KH420DK0ICA  capemaychristy   \n",
      "\n",
      "                                             summary  unixReviewTime  \n",
      "0                                     Magnetic board    1.390954e+09  \n",
      "1  it works pretty good for moving to different a...    1.395965e+09  \n",
      "2                                         love this!    1.359331e+09  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Toys_and_Games.csv')\n",
    "print df.shape\n",
    "print df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive Statistics\n",
    "\n",
    "Let's take a look at the distribution of scores across reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11ee9aa50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAECCAYAAAAVYxsVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b61c450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['overall'].value_counts().plot(kind='bar', color='cornflowerblue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "\n",
    "Naive Bayes, in short, uses Bayes rule to find the most likely class for each document. In order to do this it makes a couple of strong assumptions that it is worth being aware of: the position of each word in a document doesn't matter (bag of words), and feature probabilities are independent given the class (conditional independence). Jurafsky and Manning have a great introduction to [Naive Bayes and sentiment analysis](https://www.youtube.com/watch?v=c3fnHA6yLeY&list=PL6397E4B26D00A269&index=24). Kevin Markham has [slides](https://github.com/justmarkham/pycon-2016-tutorial) and accompanying [talk](https://www.youtube.com/watch?v=WHocRqT-KkU) that give an introduction to Naive Bayes in scikit-learn.\n",
    "\n",
    "First, drop observations containg NaN in review or star rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "49973\n",
      "49973\n"
     ]
    }
   ],
   "source": [
    "print len(df)\n",
    "df = df[df['reviewText'].notnull()]\n",
    "print len(df)\n",
    "df = df[df['overall'].notnull()]\n",
    "print len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into test and training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['reviewText'], \n",
    "                                                   df['overall'],\n",
    "                                                   test_size=.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to represent each review as a bag of words, that is, a count of how many times each word appears in a document. Therefore, convert the collection of training reviews into a collection of token counts (a document term matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number words in training corpus: 36897\n"
     ]
    }
   ],
   "source": [
    "# instantiate the vectorizer\n",
    "vect = CountVectorizer()\n",
    "\n",
    "# tokenize train and test text data\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "print \"number words in training corpus:\", len(vect.get_feature_names())\n",
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate and train a multinomial naive Bayes model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "%time nb.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make class predictions\n",
    "y_pred = nb.predict(X_test_dtm)\n",
    "\n",
    "# calculate accuracy, precision, recall, and F-measure of class predictions\n",
    "def eval_predictions(y_test, y_pred):\n",
    "    print 'accuracy:', metrics.accuracy_score(y_test, y_pred)\n",
    "    print 'precision:', metrics.precision_score(y_test, y_pred, average='weighted')\n",
    "    print 'recall:', metrics.recall_score(y_test, y_pred, average='weighted')\n",
    "    print 'F-measure:', metrics.f1_score(y_test, y_pred, average='weighted')\n",
    "eval_predictions(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at examples where the model is getting it wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print message text for the first 3 false positives\n",
    "print 'False positives:'\n",
    "print\n",
    "for x in X_test[y_test < y_pred][:2]:\n",
    "    print x\n",
    "    print\n",
    "\n",
    "# print message text for the first 3 false negatives\n",
    "print 'False negatives:'\n",
    "print\n",
    "for x in X_test[y_test > y_pred][:2]:\n",
    "    print x[:500]\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving Preprocessing\n",
    "\n",
    "Tokenization is usually accompanied by other preprocessing steps, such as:\n",
    "<ol>\n",
    "<li><i>Make all words lowercase</i></li>\n",
    "<li><i>Remove punctuation</i></li>\n",
    "<li><i>Tokenize</i>: divide string into a list of substrings.</li>\n",
    "<li><i>Remove words not containing letters</i></li>\n",
    "<li><i>Remove words containing numbers</i></li>\n",
    "<li><i>Remove stopwords</i>: stopwords are a list of high frequency words like, the, to, and also.</li>\n",
    "<li><i>Lemmatize</i>: reduces the dimension of the data by aggregating words that either are the same root or have the same meaning.</li>\n",
    "</ol>\n",
    "\n",
    "Let's try including some of these steps and see if it improves our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d7f08ca22799>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# tokenize train and test text data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mvect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprep_review\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mX_train_dtm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0mX_test_dtm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sambarrows/anaconda2/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m--> 869\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sambarrows/anaconda2/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sambarrows/anaconda2/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[0;32m--> 266\u001b[0;31m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-d7f08ca22799>\u001b[0m in \u001b[0;36mprep_review\u001b[0;34m(review)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mlower_case\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mno_punct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mno_punctuation_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlower_case\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_punct\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# weird to tokenize within the vectorizer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;31m# but not sure how else to apply functions to each token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mhas_letters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[a-zA-Z]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sambarrows/anaconda2/lib/python2.7/site-packages/nltk/tokenize/__init__.pyc\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     return [token for sent in sentences\n\u001b[0;32m--> 132\u001b[0;31m             for token in _treebank_word_tokenizer.tokenize(sent)]\n\u001b[0m",
      "\u001b[0;32m/Users/sambarrows/anaconda2/lib/python2.7/site-packages/nltk/tokenize/treebank.pyc\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, convert_parentheses, return_str)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mregexp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCONTRACTIONS2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr' \\1 \\2 '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mregexp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCONTRACTIONS3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr' \\1 \\2 '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def no_punctuation_unicode(text):\n",
    "    '''.translate only takes str. Therefore, to use .translate in the \n",
    "    tokenizer in TfidfVectorizer I need to write a function that converts \n",
    "    unicode -> string, applies .translate, and then converts it back'''\n",
    "    str_text = str(text)\n",
    "    no_punctuation = str_text.translate(None, string.punctuation)\n",
    "    unicode_text = no_punctuation.decode('utf-8')\n",
    "    return unicode_text\n",
    "\n",
    "def hasNumbers(inputString):\n",
    "    return any(char.isdigit() for char in inputString)\n",
    "\n",
    "stoplist = [word.decode('utf-8') for word in nltk.corpus.stopwords.words('english')] \n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "def prep_review(review):\n",
    "    lower_case = review.lower()\n",
    "    no_punct = no_punctuation_unicode(lower_case)\n",
    "    tokens = nltk.word_tokenize(no_punct)    # weird to tokenize within the vectorizer, \n",
    "    # but not sure how else to apply functions to each token\n",
    "    has_letters = [t for t in tokens if re.search('[a-zA-Z]',t)]\n",
    "    drop_numbers  = [t for t in has_letters if not hasNumbers(t)]\n",
    "    drop_stops = [t for t in drop_numbers if not t in stoplist] \n",
    "    lemmed = [wnl.lemmatize(word) for word in drop_stops]\n",
    "    return lemmed\n",
    "\n",
    "# tokenize train and test text data\n",
    "vect = CountVectorizer(tokenizer=prep_review)\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate and train model\n",
    "nb = MultinomialNB()\n",
    "%time nb.fit(X_train_dtm, y_train)\n",
    "\n",
    "# evaluate model\n",
    "y_pred = nb.predict(X_test_dtm)\n",
    "eval_predictions(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The extra preprocessing has little effect. In fact, our original approach did slightly better. But can we improve with a different algorithm?\n",
    "\n",
    "# Support Vector Machines\n",
    "\n",
    "I will also try classifying the reviews using SVMs, which perform classification by constructing hyperplanes to separate different classes. In constructing the hyperplanes, SVMs try firstly to classify observations correctly, and subject to this constraint seek to maximize the margin (the distance between the hyperplane and the nearest point).\n",
    "\n",
    "I start by creating a TF-IDF matrix. Rather than just measuring the number of times a word appears in a document, as we did above, we now multiply this by the inverse document frequency (the inverse of the number of documents the words appears in). Thus, a words TF-IDF is a measure of relevance. As above, I will initially use limited preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer_1 = TfidfVectorizer(min_df=5, max_df=0.8)\n",
    "tfidf_train_1 = tfidf_vectorizer_1.fit_transform(X_train)\n",
    "tfidf_test_1 = tfidf_vectorizer_1.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM is a classifier built on giving us linear separation. Kernels are the main technique for adapting SVMs to develop non-linear classifiers, by taking a low-dimensional input space and mapping it to a higher dimensional space. Let‚Äôs try SVM with both a linear kernel and an rbf (Gaussian) kernel that maps the features to a higher dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate and train model, kernel=rbf \n",
    "svm_rbf = svm.SVC(random_state=12345)\n",
    "%time svm_rbf.fit(tfidf_train_1, y_train)\n",
    "\n",
    "# evaulate model\n",
    "y_pred_1 = svm_rbf.predict(tfidf_test_1)\n",
    "eval_predictions(y_test, y_pred_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate and train model, kernel=linear\n",
    "svm_rbf = svm.SVC(kernel='linear', random_state=12345)\n",
    "%time svm_rbf.fit(tfidf_train_1, y_train)\n",
    "\n",
    "# evaulate model\n",
    "y_pred_1 = svm_rbf.predict(tfidf_test_1)\n",
    "eval_predictions(y_test, y_pred_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try with the more extensive preprocessing that we used above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer_2 = TfidfVectorizer(tokenizer=prep_review, min_df=5, max_df=0.8)\n",
    "tfidf_train_2 = tfidf_vectorizer_2.fit_transform(X_train)\n",
    "tfidf_test_2 = tfidf_vectorizer_2.transform(X_test)\n",
    "\n",
    "# kernel=rbf\n",
    "print 'kernel=rbf'\n",
    "svm_rbf = svm.SVC(random_state=1)\n",
    "%time svm_rbf.fit(tfidf_train_2, y_train)\n",
    "y_pred_2 = svm_rbf.predict(tfidf_test_2)\n",
    "eval_predictions(y_test, y_pred_2)\n",
    "print \n",
    "\n",
    "print 'kernel=linear'\n",
    "svm_rbf = svm.SVC(kernel='linear', random_state=1)\n",
    "%time svm_rbf.fit(tfidf_train_2, y_train)\n",
    "y_pred_2 = svm_rbf.predict(tfidf_test_2)\n",
    "eval_predictions(y_test, y_pred_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is suprising that with an rbf kernel we get exactly the same performance with and without the extra preprocessing steps. I have recoded the variables to ensure I'm not accidentally repeating anything. Let's also print the two vectorizers to check that they are in fact different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compare_tokens = pd.DataFrame(\n",
    "    {'unprocessed': tfidf_vectorizer_1.get_feature_names()[:10],\n",
    "     'preprocessed': tfidf_vectorizer_2.get_feature_names()[:10],\n",
    "    })\n",
    "compare_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the linear kernel performs best across all predictive measures, and that we actually get slightly better performance without preprocessing. Linear kernels often perform well with text classification because when there are a lot of features, mapping the data to a higher dimensional space [does little to improve performance](http://www.svm-tutorial.com/2014/10/svm-linear-kernel-good-text-classification/).\n",
    "\n",
    "Can we do better using grid search to optimze the hyperparameters of the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomized search\n",
    "param_dist = {'C': scipy.stats.expon(scale=100), 'gamma': scipy.stats.expon(scale=.1)}\n",
    "n_iter_search = 1\n",
    "rand_search = RandomizedSearchCV(svm.SVC(random_state=1), param_dist, cv=5, n_iter=n_iter_search)\n",
    "rand_search.fit(tfidf_train_1, y_train)\n",
    "bp = rand_search.best_params_\n",
    "print 'Best parameters:', bp\n",
    "\n",
    "# fit and evaluate model with parameters from grid search\n",
    "model = svm.SVC(C = bp['C'], gamma = bp['gamma'], random_state=1)\n",
    "model.fit(tfidf_train_1, y_train)\n",
    "y_pred = model.predict(tfidf_test_1)\n",
    "eval_predictions(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "The most striking findings here are that it preprocessing makes little difference to the performance of our algorithms and that both naive Bayes and SVMs perform similarly to one another. The latter finding, in particular, is a surprise. Whilst previous research by [Banko and Brill](http://ucrel.lancs.ac.uk/acl/P/P01/P01-1005.pdf) has shown that classifiers perform similarly to one another on extremely large corpora, I was not expecting such similar results with our relatively small sample.\n",
    "\n",
    "If I have time to pursue this project further, there are a number of steps I would like to take:\n",
    "* explore how unusual it is to have these different models and classifiers perform so similarly, and triple-check that there is no issue with my code\n",
    "* improve my classifiers, starting by looking at examples that are misclassified\n",
    "* experiment with other classifiers\n",
    "* run my models with a larger dataset, ideally, with 142.8 million reviews in McAuley's full dataset"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
